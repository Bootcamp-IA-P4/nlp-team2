import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

import pandas as pd
from feature_engineering import ToxicityFeatureExtractor
from data_preprocessing import load_and_preprocess_data

def demo_feature_engineering():
    """DemostraciÃ³n del nuevo sistema de feature engineering"""
    
    print("ğŸš€ DEMO: FEATURE ENGINEERING AVANZADO PARA TOXICIDAD")
    print("="*60)
    
    # 1. Cargar datos - RUTA CORREGIDA
    print("ğŸ“Š 1. Cargando datos...")
    df, toxicity_columns = load_and_preprocess_data('data/raw/youtoxic_english_1000.csv')
    print(f"   âœ… Datos cargados: {df.shape}")
    
    # 2. Crear extractor de caracterÃ­sticas
    print("\nğŸ”§ 2. Inicializando extractor de caracterÃ­sticas...")
    extractor = ToxicityFeatureExtractor(max_features=1000)  # Menos features para demo
    print("   âœ… Extractor inicializado")
    
    # 3. Usar una muestra pequeÃ±a para la demo
    sample_df = df.head(100).copy()
    print(f"\nğŸ“‹ 3. Usando muestra de {len(sample_df)} comentarios para demo...")
    
    # 4. Extraer caracterÃ­sticas bÃ¡sicas
    print("\nğŸ“ 4. Extrayendo caracterÃ­sticas bÃ¡sicas...")
    basic_features = extractor.add_basic_text_features(sample_df)
    basic_cols = ['text_length', 'word_count', 'avg_word_length', 'exclamation_count', 
                  'caps_ratio', 'special_char_count']
    print("   âœ… CaracterÃ­sticas bÃ¡sicas:")
    print(basic_features[basic_cols].describe())
    
    # 5. Extraer caracterÃ­sticas de sentimiento
    print("\nğŸ˜Š 5. Extrayendo caracterÃ­sticas de sentimiento...")
    sentiment_features = extractor.add_sentiment_features(sample_df)
    sentiment_cols = ['sentiment_compound', 'sentiment_positive', 'sentiment_negative', 'sentiment_neutral']
    print("   âœ… CaracterÃ­sticas de sentimiento:")
    print(sentiment_features[sentiment_cols].describe())
    
    # 6. Extraer caracterÃ­sticas de toxicidad
    print("\nğŸ’€ 6. Extrayendo caracterÃ­sticas especÃ­ficas de toxicidad...")
    toxicity_features = extractor.add_toxicity_features(sample_df)
    toxicity_cols = ['toxic_word_count', 'toxic_word_ratio', 'all_caps_words', 'toxic_density']
    print("   âœ… CaracterÃ­sticas de toxicidad:")
    print(toxicity_features[toxicity_cols].describe())
    
    # 7. Extraer todas las caracterÃ­sticas
    print("\nğŸ¯ 7. Extrayendo TODAS las caracterÃ­sticas...")
    all_features = extractor.extract_all_features(sample_df)
    print(f"   âœ… Dataset final: {all_features.shape}")
    print(f"   ğŸ“Š CaracterÃ­sticas originales: {sample_df.shape[1]}")
    print(f"   ğŸ†• Nuevas caracterÃ­sticas: {all_features.shape[1] - sample_df.shape[1]}")
    
    # 8. AnÃ¡lisis de caracterÃ­sticas mÃ¡s discriminativas
    print("\nğŸ” 8. AnÃ¡lisis de caracterÃ­sticas discriminativas...")
    
    # Comparar comentarios tÃ³xicos vs no tÃ³xicos
    toxic_comments = all_features[all_features['IsToxic'] == True]
    non_toxic_comments = all_features[all_features['IsToxic'] == False]
    
    discriminative_features = {}
    for col in ['toxic_word_ratio', 'sentiment_negative', 'caps_ratio', 'exclamation_count']:
        if col in all_features.columns:
            toxic_mean = toxic_comments[col].mean()
            non_toxic_mean = non_toxic_comments[col].mean()
            difference = abs(toxic_mean - non_toxic_mean)
            discriminative_features[col] = {
                'toxic_mean': toxic_mean,
                'non_toxic_mean': non_toxic_mean,
                'difference': difference
            }
    
    print("   ğŸ“ˆ CaracterÃ­sticas mÃ¡s discriminativas:")
    for feature, stats in sorted(discriminative_features.items(), 
                                key=lambda x: x[1]['difference'], reverse=True):
        print(f"     ğŸ¯ {feature}:")
        print(f"        TÃ³xicos: {stats['toxic_mean']:.3f}")
        print(f"        No tÃ³xicos: {stats['non_toxic_mean']:.3f}")
        print(f"        Diferencia: {stats['difference']:.3f}")
    
    # 9. Ejemplos de comentarios con caracterÃ­sticas extremas
    print("\nğŸ“ 9. Ejemplos de comentarios con caracterÃ­sticas extremas...")
    
    if 'toxic_word_ratio' in all_features.columns:
        # Comentario con mÃ¡s palabras tÃ³xicas
        max_toxic_idx = all_features['toxic_word_ratio'].idxmax()
        max_toxic_comment = all_features.loc[max_toxic_idx]
        print(f"\n   ğŸ”¥ Comentario con mÃ¡s palabras tÃ³xicas ({max_toxic_comment['toxic_word_ratio']:.2%}):")
        print(f"      \"{max_toxic_comment['Text_Clean'][:100]}...\"")
        print(f"      Es tÃ³xico: {max_toxic_comment['IsToxic']}")
    
    if 'sentiment_negative' in all_features.columns:
        # Comentario mÃ¡s negativo
        max_negative_idx = all_features['sentiment_negative'].idxmax()
        max_negative_comment = all_features.loc[max_negative_idx]
        print(f"\n   ğŸ˜¢ Comentario mÃ¡s negativo ({max_negative_comment['sentiment_negative']:.3f}):")
        print(f"      \"{max_negative_comment['Text_Clean'][:100]}...\"")
        print(f"      Es tÃ³xico: {max_negative_comment['IsToxic']}")
    
    print("\nâœ… DEMO COMPLETADA")
    print("="*60)
    print("ğŸ’¡ El nuevo feature engineering incluye:")
    print("   ğŸ”¤ CaracterÃ­sticas bÃ¡sicas de texto (longitud, palabras, etc.)")
    print("   ğŸ˜Š AnÃ¡lisis de sentimiento (VADER)")
    print("   ğŸ’€ CaracterÃ­sticas especÃ­ficas de toxicidad")
    print("   ğŸ“Š TF-IDF vectorization")
    print("   ğŸ”¤ N-gramas de caracteres")
    print(f"\nğŸ“ˆ Total de caracterÃ­sticas generadas: {all_features.shape[1]}")
    
    return all_features

if __name__ == "__main__":
    demo_feature_engineering()
